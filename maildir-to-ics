#!/usr/bin/env python
# -*- coding: utf-8 -*-
# vim: set ts=4 sw=4 et:
#
# Copyright (c) 2013 Vincent Untz <vincent@vuntz.net>
#
# License: MIT
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.
#


import errno
import os
import string
import sys

import ConfigParser
import calendar
import datetime
import email
import hashlib
import io
import optparse
import re
import shutil
import time


'''
Notes:
  - we do not use python-vobject for parsing vEvents, to allow using this
    without any other dependency than python.
  - we keep VTIMEZONE objects (but only the first one we meet with a given
    TZID) and we output only the ones that are in use by the vEvents.

How this works:
  - we have a cache of extracted vEvents/vTimezones from the maildir, to avoid
    re-parsing all mails all the time. We use a "recursive checksum" to
    validate that cache.
  - we also have caches of DTSTART/DTEND and of used vTimezones for each
    vEvent, to avoid re-parsing the extracted vEvents. We also use a checksum
    to validate these caches.
  - we avoid rebuilding the iCalendar file if the caches are valid, and the
    time period for the vEvents to consider didn't change.
  - we simply concatenate all files together to build the resulting iCalendar
    file.
'''


ADD_ALARM = False
BROKEN_UTF8 = False
PREVIOUS_RUN_FILE_SECTION = 'file previous'
PREVIOUS_RUN_DIR_SECTION = 'dir previous'
VERBOSE = 0
VEVENTS_DATES = {}
VEVENTS_TZIDS = {}


def verbose_print(s, level=1):
    global VERBOSE
    if VERBOSE >= level:
        print s


class LineUnwrapper:
    def __init__(self, s):
        self.lines = s.split('\n')
        self.lines_read = None
        self.saved = None

    def each_line(self):
        for line in self.lines:
            line = line.rstrip('\r')
            if line.startswith(' ') or line.startswith('\t'):
                if self.saved is None:
                    self.saved = ''
                    self.lines_read = []
                self.lines_read.append(line)
                self.saved += line.strip()
            else:
                if self.saved is not None:
                    retval = (self.lines_read, self.saved)
                    self.lines_read = [line]
                    self.saved = line.strip()
                    yield retval
                self.lines_read = [line]
                self.saved = line.strip()


def hash_from_file(filename):
    file_hash = hashlib.md5()

    fb = open(filename, 'rb')
    while True:
        buf = fb.read(4096)
        if not buf:
            break
        file_hash.update(buf)

    fb.close()

    return file_hash.hexdigest()


def hash_from_dir(directory):
    dir_hash = hashlib.md5()

    # We always need to examine files in the same order to make sure the hash
    # is always computed the same way
    filenames = os.listdir(directory)
    filenames.sort()

    for filename in filenames:
        path = os.path.join(directory, filename)
        if os.path.isdir(path):
            dir_hash.update(hash_from_dir(path))
        elif os.path.isfile(path):
            dir_hash.update(hash_from_file(path))
        else:
            verbose_print('Skipping compute of hash of \'%s\': not a file nor '
                          'a directory.' % path, 1)

    return dir_hash.hexdigest()


def extract_tzid(prop, line):
    try:
        tzid = None
        params = line[len(prop + ';'):line.rfind(':')]
        for param in params.split(';'):
            if not param.startswith('TZID='):
                continue

            tzid = param[len('TZID='):]
            break

        return tzid
    except Exception, e:
        print >>sys.stderr, 'Cannot extract timezone ' \
                            'in line \'%s\': %s.' % (line, e)
        return None


def id_to_filename(unfiltered_id):
    return filter(lambda x: x in string.printable and x != '/' and x != '"',
                  unfiltered_id)


def save_vevent(mail, vevent, uid,
                rrule, dtstamp, dtstart, dtend, tzids, save_dir):
    global VEVENTS_DATES
    global VEVENTS_TZIDS

    if uid:
        filename = id_to_filename(uid)
    else:
        print >>sys.stderr, 'Ignoring event with no UID in \'%s\'' % mail
        return

    if dtstart is None:
        dtstart = dtend
    elif dtend is None:
        dtend = dtstart

    if dtstart is None:
        print >>sys.stderr, 'Ignoring event with no DTSTART in \'%s\'' % mail
        return

    path = os.path.join(save_dir, filename)
    if os.path.exists(path):
        old_dtstamp = None

        fb = open(path)
        content = LineUnwrapper(fb.read())
        lines = fb.readlines()
        fb.close()

        for (real_lines, line) in content.each_line():
            if not line.startswith('DTSTAMP:'):
                continue
            old_dtstamp = line[len('DTSTAMP:'):]
            break

        if dtstamp > old_dtstamp:
            verbose_print('Duplicate event \'%s\' with newer DTSTAMP, '
                          'overwriting.' % uid, 2)
        else:
            verbose_print('Duplicate event \'%s\' with same or older DTSTAMP, '
                          'not overwriting.' % uid, 2)
            return

    VEVENTS_DATES[filename] = (dtstart, dtend)
    if len(tzids) > 0:
        VEVENTS_TZIDS[filename] = tzids

    if rrule is not None:
        if type(rrule) in (str, unicode):
            # FIXME: Not fully correct: rrule is the last dtstart, not the last dtend
            VEVENTS_DATES[filename] = (dtstart, rrule)
        # all day events might be recurring too
        elif len(dtend) >= len('19700101'):
            try:
                (freq, count) = rrule
                if count is None:
                    # event is forever; we pretend it will stop in 100 years
                    freq = 'YEARLY'
                    count = 100

                year = int(dtend[0:4])
                month = int(dtend[4:6])
                day = int(dtend[6:8])
                date_dtend = datetime.date(year, month, day)

                if freq == 'DAILY':
                    delta = datetime.timedelta(days=count)
                    date_dtend += delta
                elif freq == 'WEEKLY':
                    delta = datetime.timedelta(days=count*7)
                    date_dtend += delta
                elif freq == 'MONTHLY':
                    # Based on http://stackoverflow.com/questions/4130922/how-to-increment-datetime-month-in-python
                    # We could use the dateutil module, but let's not add a dependency
                    month = month - 1 + count
                    year = year + month / 12
                    month = month % 12 + 1
                    day = min(day, calendar.monthrange(year, month)[1])
                    date_dtend = datetime.date(year, month, day)
                elif freq == 'YEARLY':
                    year += count
                    date_dtend = datetime.date(year, month, day)
                rrule_dtend = date_dtend.strftime('%Y%m%d')
                VEVENTS_DATES[filename] = (dtstart, rrule_dtend)
            except:
                verbose_print('Cannot parse RRULE \'%s\' in event ' \
                              '\'%s\'.' % (rrule, uid), 1)
        else:
            verbose_print('Cannot parse RRULE \'%s\' in event ' \
                          '\'%s\'.' % (rrule, uid), 1)

    fp = open(path, 'w')
    fp.write(vevent.encode('utf-8'))
    fp.close()


def save_vtimezone(mail, vtimezone, tzid, save_dir):
    if tzid:
        filename = id_to_filename(tzid)
    else:
        print >>sys.stderr, 'Ignoring timezone with no TZID in \'%s\'' % mail
        return

    path = os.path.join(save_dir, filename)
    if os.path.exists(path):
        verbose_print('Timezone \'%s\' already exists, not ' \
                      'overwriting.' % tzid.encode('utf-8'),
                      3)
        return

    fp = open(path, 'w')
    fp.write(vtimezone.encode('utf-8'))
    fp.close()


def save_events_from_vcalendar(mail, vcalendar, vevents_save_dir, vtimezones_save_dir):
    global ADD_ALARM

    content = LineUnwrapper(vcalendar)

    vtimezone = None
    tzid = None

    vevent = None
    uid = None
    rrule = None
    dtstamp = None
    dtstart = None
    dtend = None
    used_tzids = set()

    need_valarm = ADD_ALARM
    valarm = '''BEGIN:VALARM
ACTION:DISPLAY
DESCRIPTION:REMINDER
TRIGGER;RELATED=START:-PT5M
END:VALARM'''
    # We don't add alarms for the past; while technically, we should not do
    # that since this means regenerating the ics with the same mails on
    # different days will have different results, in practice this is no big
    # deal and this avoids unneeded modifications.
    # Two days in the past; this avoids any issue with timezones ;-)
    yesterday = (datetime.datetime.now() - datetime.timedelta(days=2))
    no_alarm_before = yesterday.strftime('%Y%m%d')

    for (real_lines, line) in content.each_line():
        if vevent is not None:
            # FIXME: we should really inline the attachment from the mime part,
            # instead of dropping this line
            if line == 'ATTACH:CID:...':
                continue
            vevent.extend(real_lines)
            # FIXME: what if there's a duplicate UID/DTSTAMP/etc. line? Is it
            # correct to only keep first one?
            if line == 'END:VEVENT':
                # FIXME: generate UID if none?
                if need_valarm:
                    # insert before the END:VEVENT
                    vevent.insert(-len(real_lines), valarm)
                # Append final \n for EOL
                save_vevent(mail, '\n'.join(vevent) + '\n', uid,
                            rrule, dtstamp, dtstart, dtend, used_tzids,
                            vevents_save_dir)
                vevent = None
            elif line.startswith('UID:') and uid is None:
                uid = line[len('UID:'):]
            elif line.startswith('RRULE:') and rrule is None:
                rrule_freq = None
                rrule_count = None
                rrule_skip = False
                for param in line[len('RRULE:'):].split(';'):
                    if param.startswith('UNTIL='):
                        rrule = param[len('UNTIL='):]
                        break
                    elif param.startswith('FREQ='):
                        rrule_freq = param[len('FREQ='):].upper()
                        if not rrule_freq in ('DAILY', 'WEEKLY', \
                                              'MONTHLY', 'YEARLY'):
                            verbose_print('Ignoring RRULE with minor FREQ ' \
                                          '\'%s\'.' % rrule_freq, 2)
                            rrule_skip = True
                    elif param.startswith('COUNT='):
                        try:
                            rrule_count = int(param[len('COUNT='):])
                        except ValueError:
                            verbose_print('Cannot parse COUNT in RRULE ' \
                                          '\'%s\'.' % line, 1)
                            rrule_skip = True
                if rrule is None and not rrule_skip and rrule_freq is not None:
                    rrule = (rrule_freq, rrule_count)
            elif line.startswith('DTSTAMP:') and dtstamp is None:
                dtstamp = line[len('DTSTAMP:'):]
            elif line.startswith('DTSTART:') and dtstart is None:
                dtstart = line[len('DTSTART:'):]
                if len(dtstart) == len('19700101'):
                    # broken vEvent: default value type is DATE-TIME
                    new_line = 'DTSTART;VALUE=DATE:%s' % dtstart
                    if len(real_lines) == 1:
                        vevent[-1] = new_line
                    else:
                        vevent = vevent[:-len(real_lines)]
                        vevent.append(new_line)
                if need_valarm:
                    # event with a all-day DTSTART are most-likely all-day
                    # events
                    if len(dtstart) == len('19700101'):
                        need_valarm = False
                    elif dtstart < no_alarm_before:
                        need_valarm = False
            elif line.startswith('DTSTART;') and dtstart is None:
                dtstart = line[line.rfind(':') + 1:]
                dtstart_tzid = extract_tzid('DTSTART', line)
                if dtstart_tzid is not None:
                    used_tzids.add(dtstart_tzid)
                if need_valarm:
                    # event with a all-day DTSTART are most-likely all-day
                    # events
                    if len(dtstart) == len('19700101'):
                        need_valarm = False
                    elif dtstart < no_alarm_before:
                        need_valarm = False
            elif line.startswith('DTEND:') and dtend is None:
                dtend = line[len('DTEND:'):]
                if len(dtend) == len('19700101'):
                    # broken vEvent: default value type is DATE-TIME
                    new_line = 'DTEND;VALUE=DATE:%s' % dtend
                    if len(real_lines) == 1:
                        vevent[-1] = new_line
                    else:
                        vevent = vevent[:-len(real_lines)]
                        vevent.append(new_line)
            elif line.startswith('DTEND;') and dtend is None:
                dtend = line[line.rfind(':') + 1:]
                dtend_tzid = extract_tzid('DTEND', line)
                if dtend_tzid is not None:
                    used_tzids.add(dtend_tzid)
            elif need_valarm:
                if line.startswith('X-GWITEM-TYPE:'):
                    value = line[len('X-GWITEM-TYPE:'):].lower()
                    if value != 'appointment':
                        need_valarm = False
                elif line.startswith('X-GWALLDAYEVENT:'):
                    value = line[len('X-GWALLDAYEVENT:'):].lower()
                    if value == 'true':
                        need_valarm = False
                elif line.startswith('X-MICROSOFT-CDO-ALLDAYEVENT:'):
                    value = line[len('X-MICROSOFT-CDO-ALLDAYEVENT:'):].lower()
                    if value == 'true':
                        need_valarm = False
                elif line == 'BEGIN:VALARM':
                    need_valarm = False
        elif vtimezone is not None:
            vtimezone.extend(real_lines)
            if line == 'END:VTIMEZONE':
                # Append final \n for EOL
                save_vtimezone(mail, '\n'.join(vtimezone) + '\n', tzid,
                               vtimezones_save_dir)
                vtimezone = None
            elif line.startswith('TZID:') and tzid is None:
                tzid = line[len('TZID:'):]
        elif line == 'BEGIN:VEVENT':
            vevent = real_lines
            uid = None
            rrule = None
            dtstamp = None
            dtstart = None
            dtend = None
            used_tzids = set()
            need_valarm = ADD_ALARM
        elif line == 'BEGIN:VTIMEZONE':
            vtimezone = real_lines
            tzid = None

    if vevent is not None or vtimezone is not None:
        verbose_print('Invalid vCalendar in \'%s\'.' % mail, 2)


def save_vcalendar(filename, msg, charset, part_number, vcalendar, dest_dir):
    message_id = msg['message-id']
    if not message_id:
        verbose_print('Mail \'%s\' has no Message-ID header.' % filename, 1)
        message_id = os.path.basename(filename)

    if message_id[0] == '<':
        message_id = message_id[1:]
    if message_id[-1] == '>':
        message_id = message_id[:-1]

    # FIXME: there must be a better way than hard-coding this
    if len(message_id) > 253:
        verbose_print('Mail \'%s\' generates vCalendar files with a filename '
                      'too long.' % filename, 1)
        message_id = os.path.basename(filename)
        if len(message_id) > 253:
            message_id = message_id[:-2]

    basename = "%s-%s" % (message_id, part_number)

    filename = os.path.join(dest_dir, basename)
    fp = open(filename, 'w')
    fp.write(vcalendar.encode(charset))
    fp.close()


def save_events_from_mail(filename, file_args, dir_args):
    global BROKEN_UTF8

    if not os.path.exists(filename):
        print >>sys.stderr, 'Non-existing mail \'%s\'???' % filename
        return

    fp = open(filename)
    msg = email.message_from_file(fp)
    fp.close()

    part_number = 0

    for part in msg.walk():
        if part.get_content_type() != 'text/calendar':
            continue

        part_number += 1

        charset = part.get_content_charset('ascii').lower()
        vcalendar = part.get_payload(decode=True).decode(charset)

        # This is really really ugly. We detect that we have a broken utf8 if
        # we have some unicode character in the decoded string.
        if charset == 'utf-8' and BROKEN_UTF8 and u'\xc3' in vcalendar:
            decoded = vcalendar

            # replace characters that got killed in MIME
            ## à
            decoded = decoded.replace(u'\xc3\x20', u'\xc3\xa0')
            ## è
            decoded = decoded.replace(u'\xc3\u0308', u'\xc3\xa8')
            ## ô
            decoded = decoded.replace(u'\xc3\u0301', u'\xc3\xb4')

            encoded = None
            for encoding in ['cp1252', 'iso-8859-15']:
                try:
                    encoded = decoded.encode(encoding)
                except UnicodeEncodeError:
                    continue
                break

            if encoded is None:
                # if we hit this, we finish breaking the UTF-8, and we'll have
                # the verbose_print from the last UnicodeDecodeError
                encoded = decoded.encode('iso-8859-15', 'replace')

            # we use 'replace' for the last decode since if we reached that
            # state, then there's simply nothing we can do to fix the UTF-8:
            # it's just plainly broken, not just double-encoded.
            try:
                reencoded = encoded.decode('utf-8')
            except UnicodeDecodeError:
                verbose_print('Mail \'%s\' contains really broken UTF-8.' %
                              filename, 1)
                reencoded = encoded.decode('utf-8', 'replace')

            vcalendar = reencoded

        if file_args:
            save_events_from_vcalendar(filename, vcalendar,
                                       file_args['vevents_save_dir'],
                                       file_args['vtimezones_save_dir'])
        if dir_args:
            save_vcalendar(filename, msg, charset, part_number, vcalendar,
                           dir_args['dest_dir'])


def save_events_from_mails_in_dir(directory, file_args = None, dir_args = None):
    if not os.path.isdir(directory):
        print >>sys.stderr, 'Non-existing Maildir subdirectory ' \
                            '\'%s\'???' % directory
        return

    for filename in os.listdir(directory):
        path = os.path.join(directory, filename)
        if not os.path.isfile(path):
            verbose_print('Skipping \'%s\': not a file.' % path, 1)
            continue
        save_events_from_mail(path, file_args, dir_args)


def save_events_from_maildir(directory, file_args = None, dir_args = None):
    for subdir in ['cur', 'new', 'tmp']:
        path = os.path.join(directory, subdir)
        save_events_from_mails_in_dir(path, file_args, dir_args)


def write_ics_from_dir(vevents_directory, vtimezones_directory, dest, limit_past, limit_future):
    global VEVENTS_DATES
    global VEVENTS_TZIDS

    relevant_vevents = []
    relevant_tzid = set()

    filenames = os.listdir(vevents_directory)
    # sort to try to keep the generated file consistent if re-generated
    filenames.sort()

    for filename in filenames:
        if filename in VEVENTS_DATES:
            (dtstart, dtend) = VEVENTS_DATES[filename]
            if dtstart > limit_future:
                verbose_print('Skipping event \'%s\': too distant '
                              'in the future.' % filename, 3)
                continue
            if dtend < limit_past:
                verbose_print('Skipping event \'%s\': too distant '
                              'in the past.' % filename, 3)
                continue

        relevant_vevents.append(filename)
        if filename in VEVENTS_TZIDS:
            relevant_tzid.update(VEVENTS_TZIDS[filename])

    if dest is not None:
        fp = io.open(dest, 'w', newline='\r\n')
    else:
        fp = sys.stdout

    fp.write(u'BEGIN:VCALENDAR\n')
    fp.write(u'VERSION:2.0\n')
    fp.write(u'PRODID:-//Vincent Untz//NONSGML maildir-to-ics//EN\n')

    for tzid in sorted(list(relevant_tzid)):
        path = os.path.join(vtimezones_directory, id_to_filename(tzid))
        if not os.path.exists(path):
            verbose_print('Non-existing vTimezone referenced with \'%s\'.' % tzid, 1)
            continue
        timezone = io.open(path, 'r')
        while True:
            buf = timezone.read(4096)
            if not buf:
                break
            fp.write(buf)
        timezone.close()

    for filename in relevant_vevents:
        path = os.path.join(vevents_directory, filename)
        event = io.open(path, 'r')
        while True:
            buf = event.read(4096)
            if not buf:
                break
            fp.write(buf)
        event.close()

    fp.write(u'END:VCALENDAR\n')
    if dest is not None:
        fp.close()


def do_ics_dir(maildir, dest_ics_dir, force):
    previous_run = get_previous_run(maildir=maildir)

    old_mails_hash = None
    old_dest_ics_dir = None

    if previous_run.has_option(PREVIOUS_RUN_DIR_SECTION, 'mails'):
        old_mails_hash = previous_run.get(PREVIOUS_RUN_DIR_SECTION,
                                          'mails')
    if previous_run.has_option(PREVIOUS_RUN_DIR_SECTION, 'dest_dir'):
        old_dest_ics_dir = previous_run.get(PREVIOUS_RUN_DIR_SECTION,
                                            'dest_dir')

    new_mails_hash = hash_from_dir(maildir)

    if not force and \
        os.path.exists(dest_ics_dir) and \
        dest_ics_dir == old_dest_ics_dir and \
        new_mails_hash == old_mails_hash:
        verbose_print('No need to update directory: '
                      'no change compared to last run.', 1)
        return

    previous_run.set(PREVIOUS_RUN_DIR_SECTION, 'mails', new_mails_hash)
    previous_run.set(PREVIOUS_RUN_DIR_SECTION, 'dest_dir', dest_ics_dir)

    if not os.path.exists(dest_ics_dir):
        dirname = os.path.dirname(dest_ics_dir)
        if dirname and not os.path.exists(dirname):
            os.makedirs(dirname)
        os.mkdir(dest_ics_dir, 0700)

    dir_args = { 'dest_dir': dest_ics_dir }
    save_events_from_maildir(maildir, dir_args=dir_args)

    save_previous_run(previous_run, maildir=maildir)


def do_ics_file(maildir, dest_ics, not_before, not_after, force):
    global VEVENTS_DATES
    global VEVENTS_TZIDS

    info_dir = get_cache_dir(maildir)

    now = datetime.datetime.now()
    past = now - datetime.timedelta(days=not_before)
    future = now + datetime.timedelta(days=not_after)
    limit_past = past.strftime('%Y%m%d')
    limit_future = future.strftime('%Y%m%d')

    previous_run = get_previous_run(cache_dir=info_dir)

    old_mails_hash = None
    old_vevents_cache_hash = None
    old_vtimezones_cache_hash = None
    old_vevents_dates_hash = None
    old_vevents_tzids_hash = None
    old_add_alarm = None
    old_broken_utf8 = None
    old_limit_past = None
    old_limit_future = None
    old_ics = None

    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'mails'):
        old_mails_hash = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                          'mails')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'vevents_cache'):
        old_vevents_cache_hash = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                                  'vevents_cache')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'vtimezones_cache'):
        old_vtimezones_cache_hash = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                                     'vtimezones_cache')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'vevents_dates'):
        old_vevents_dates_hash = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                                  'vevents_dates')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'vevents_tzids'):
        old_vevents_tzids_hash = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                                  'vevents_tzids')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'add_alarm'):
        old_add_alarm = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                         'add_alarm')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'broken_utf8'):
        old_broken_utf8 = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                           'broken_utf8')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'limit_past'):
        old_limit_past = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                          'limit_past')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'limit_future'):
        old_limit_future = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                            'limit_future')
    if previous_run.has_option(PREVIOUS_RUN_FILE_SECTION, 'file'):
        old_ics = previous_run.get(PREVIOUS_RUN_FILE_SECTION,
                                   'file')

    new_mails_hash = hash_from_dir(maildir)
    previous_run.set(PREVIOUS_RUN_FILE_SECTION, 'mails', new_mails_hash)

    vevents_cache_dir = os.path.join(info_dir, 'vevents')
    vevents_cache_dir_exists = os.path.exists(vevents_cache_dir)

    vtimezones_cache_dir = os.path.join(info_dir, 'vtimezones')
    vtimezones_cache_dir_exists = os.path.exists(vtimezones_cache_dir)

    vevents_dates = os.path.join(info_dir, 'vevents_dates')
    if os.path.exists(vevents_dates):
        current_vevents_dates_hash = hash_from_file(vevents_dates)
    else:
        current_vevents_dates_hash = 'non-existing'

    vevents_tzids = os.path.join(info_dir, 'vevents_tzids')
    if os.path.exists(vevents_tzids):
        current_vevents_tzid_hash = hash_from_file(vevents_tzids)
    else:
        current_vevents_tzid_hash = 'non-existing'

    need_to_rebuild_cache = False

    if force or old_mails_hash != new_mails_hash or \
        not vevents_cache_dir_exists or \
        not vtimezones_cache_dir_exists or \
        old_vevents_dates_hash != current_vevents_dates_hash or \
        old_vevents_tzids_hash != current_vevents_tzid_hash or \
        old_add_alarm != str(ADD_ALARM) or \
        old_broken_utf8 != str(BROKEN_UTF8):
        need_to_rebuild_cache = True

    if not need_to_rebuild_cache:
        fp = open(vevents_dates, 'r')
        for line in fp.readlines():
            if line[-1] == '\n':
                line = line[:-1]
            elements = line.split('\t')
            if len(elements) != 3:
                verbose_print('Line \'%s\' in \'%s\' is ' 'invalid.' %
                              (line, vevent_dates), 1)
                # file is corrupted, we'll regenerate it
                need_to_rebuild_cache = True
                VEVENTS_DATES = {}
                break
            (uid, dtstart, dtend) = elements
            VEVENTS_DATES[uid] = (dtstart, dtend)
        fp.close()

        fp = open(vevents_tzids, 'r')
        for line in fp.readlines():
            if line[-1] == '\n':
                line = line[:-1]
            elements = line.split('\t', 2)
            if len(elements) != 2:
                verbose_print('Line \'%s\' in \'%s\' is ' 'invalid.' %
                              (line, vevent_tzid), 1)
                # file is corrupted, we'll regenerate it
                need_to_rebuild_cache = True
                VEVENTS_TZIDS = {}
                break
            (event_filename, tzids) = elements
            tzids_set = set(tzids.split('\t'))
            if len(tzids_set) > 0:
                VEVENTS_TZIDS[event_filename] = tzids_set
        fp.close()

    if need_to_rebuild_cache:
        verbose_print('Rebuilding vEvents cache.', 1)
        if vevents_cache_dir_exists:
            shutil.rmtree(vevents_cache_dir)
        os.makedirs(vevents_cache_dir)
        if vtimezones_cache_dir_exists:
            shutil.rmtree(vtimezones_cache_dir)
        os.makedirs(vtimezones_cache_dir)
        file_args = {
            'vevents_cache_dir': vevents_cache_dir,
            'vtimezones_cache_dir': vtimezones_cache_dir
        }
        save_events_from_maildir(maildir, file_args=file_args)

        new_vevents_cache_hash = hash_from_dir(vevents_cache_dir)
        previous_run.set(PREVIOUS_RUN_FILE_SECTION,
                         'vevents_cache', new_vevents_cache_hash)

        new_vtimezones_cache_hash = hash_from_dir(vtimezones_cache_dir)
        previous_run.set(PREVIOUS_RUN_FILE_SECTION,
                         'vtimezones_cache', new_vtimezones_cache_hash)

        previous_run.set(PREVIOUS_RUN_FILE_SECTION,
                         'add_alarm', str(ADD_ALARM))
        previous_run.set(PREVIOUS_RUN_FILE_SECTION,
                         'broken_utf8', str(BROKEN_UTF8))

        dates_hash = hashlib.md5()
        fp = open(vevents_dates, 'w')
        for (event_filename, (dtstart, dtend)) in VEVENTS_DATES.iteritems():
            line = '%s\t%s\t%s\n' % (event_filename, dtstart, dtend)
            fp.write(line)
            dates_hash.update(line)
        fp.close()

        new_vevents_dates_hash = dates_hash.hexdigest()
        previous_run.set(PREVIOUS_RUN_FILE_SECTION,
                         'vevents_dates', new_vevents_dates_hash)

        tzid_hash = hashlib.md5()
        fp = open(vevents_tzids, 'w')
        for (event_filename, tzids) in VEVENTS_TZIDS.iteritems():
            sorted_tzids = sorted(list(tzids))
            line = '%s\t%s\n' % (event_filename, '\t'.join(sorted_tzids))
            utf8_line = line.encode('utf-8')
            fp.write(utf8_line)
            tzid_hash.update(utf8_line)
        fp.close()

        new_vevents_tzids_hash = tzid_hash.hexdigest()
        previous_run.set(PREVIOUS_RUN_FILE_SECTION,
                         'vevents_tzids', new_vevents_tzids_hash)
    else:
        new_vevents_cache_hash = old_vevents_cache_hash
        new_vtimezones_cache_hash = old_vtimezones_cache_hash
        new_vevents_dates_hash = old_vevents_dates_hash
        new_vevents_tzids_hash = old_vevents_tzids_hash
        verbose_print('No need to rebuild vEvents cache: '
                      'no change compared to last run.', 1)

    # regenerate ics if:
    #  - --force is used
    #  - events changed
    #  - range of dates to output changed
    #  - we output to stdout (so no old version)
    #  - last generated file is not the same as the new one, so we don't know
    #    if it's up-to-date
    #
    # relatedly: no need to regenerate previous-run.ini if ics isn't
    # regenerated
    if force or old_vevents_cache_hash != new_vevents_cache_hash or \
        old_vtimezones_cache_hash != new_vtimezones_cache_hash or \
        old_vevents_dates_hash != new_vevents_dates_hash or \
        old_vevents_tzids_hash != new_vevents_tzids_hash or \
        old_limit_past != limit_past or \
        old_limit_future != limit_future or \
        dest_ics is None or \
        old_ics != dest_ics or \
        not os.path.exists(dest_ics):
        verbose_print('Regenerating vCalendar.', 1)

        try:
            write_ics_from_dir(vevents_cache_dir, vtimezones_cache_dir,
                               dest_ics, limit_past, limit_future)
        except IOError, e:
            # ignore broken pipe for stdout
            if dest_ics is None and e.errno != errno.EPIPE:
                raise e

        previous_run.set(PREVIOUS_RUN_FILE_SECTION, 'limit_past', limit_past)
        previous_run.set(PREVIOUS_RUN_FILE_SECTION, 'limit_future', limit_future)
        previous_run.set(PREVIOUS_RUN_FILE_SECTION, 'file', dest_ics or '')

        save_previous_run(previous_run, cache_dir=info_dir)
    else:
        verbose_print('No need to regenerate vCalendar: '
                      'no change compared to last run.', 1)


def get_cache_dir(maildir):
    # move to absolute path, as we use it to compute a hash
    maildir = os.path.abspath(maildir)

    fallback_xdg_cache_home = os.path.join(os.path.expanduser('~'), '.cache')
    xdg_cache_home = os.environ.get('XDG_CACHE_HOME', fallback_xdg_cache_home)
    if not os.path.exists(xdg_cache_home):
        dirname = os.path.dirname(xdg_cache_home)
        if not os.path.exists(dirname):
            os.makedirs(dirname)
        os.mkdir(xdg_cache_home, 0700)

    cache_hash = hashlib.md5()
    cache_hash.update(maildir)

    return os.path.join(xdg_cache_home, 'maildir-to-ics',
                            cache_hash.hexdigest())


def get_previous_run_path(cache_dir = None, maildir = None):
    if not cache_dir and maildir:
        cache_dir = get_cache_dir(maildir)
    if not cache_dir:
        raise Exception("No Maildir directory specified!")
    return os.path.join(cache_dir, 'previous-run.ini')


def get_previous_run(cache_dir = None, maildir = None):
    previous_run_path = get_previous_run_path(cache_dir, maildir)
    previous_run = ConfigParser.SafeConfigParser()
    if os.path.exists(previous_run_path):
        previous_run.read(previous_run_path)
    if not previous_run.has_section(PREVIOUS_RUN_FILE_SECTION):
        previous_run.add_section(PREVIOUS_RUN_FILE_SECTION)
    if not previous_run.has_section(PREVIOUS_RUN_DIR_SECTION):
        previous_run.add_section(PREVIOUS_RUN_DIR_SECTION)
    return previous_run


def save_previous_run(data, cache_dir = None, maildir = None):
    previous_run_path = get_previous_run_path(cache_dir, maildir)
    fp = open(previous_run_path, 'w')
    data.write(fp)
    fp.close()


def main(args):
    global ADD_ALARM
    global BROKEN_UTF8
    global VERBOSE

    usage_str = 'usage: %prog [options] --maildir=PATH'
    parser = optparse.OptionParser(usage=usage_str)

    parser.add_option('--maildir', dest='maildir',
                      default=None,
                      metavar="PATH",
                      help='Maildir directory to extract events from')
    parser.add_option('--ics', dest='ics',
                      default=None,
                      metavar="FILE",
                      help='iCalendar file that will be created '
                           '(if not used, will output ics to stdout)')
    parser.add_option('--ics-dir', dest='ics_dir',
                      default=None,
                      metavar="DIRECTORY",
                      help='Directory that will be populated with iCalendar'
                           'files from each mail')
    parser.add_option('--not-before', dest='not_before',
                      type='int', default=61,
                      metavar='N',
                      help='ignore events that happened before the '
                           'last N days (default: 61, ie two months)'
                           '; ignored with --ics-dir')
    parser.add_option('--not-after', dest='not_after',
                      type='int', default=182,
                      metavar='N',
                      help='ignore events that will happen after the '
                           'next N days (default: 182, ie six months)'
                           '; ignored with --ics-dir')
    parser.add_option('--add-alarm', dest='add_alarm',
                      action='store_true', default=False,
                      help='automatically add 5 minutes alarm to non-all-day '
                           'appointments'
                           '; ignored with --ics-dir')
    parser.add_option('--broken-utf8', dest='broken_utf8',
                      action='store_true', default=False,
                      help='assume that UTF-8 in mails is mis-encoded UTF-8 '
                           'in Latin-1')
    parser.add_option('--force', '-f', dest='force',
                      action='store_true', default=False,
                      help='always regenerate ics file')
    parser.add_option('--verbose', '-v', dest='verbose',
                      action='count', default=0,
                      help='be verbose; use multiple times to add more '
                           'verbosity (default: false)')

    (options, args) = parser.parse_args()

    maildir = options.maildir
    dest_ics = options.ics
    dest_ics_dir = options.ics_dir
    not_before = options.not_before
    not_after = options.not_after
    ADD_ALARM = options.add_alarm
    BROKEN_UTF8 = options.broken_utf8
    force = options.force
    VERBOSE = options.verbose

    if maildir is None:
        parser.error('--maildir argument is required')

    if not os.path.isdir(maildir):
        print >>sys.stderr, 'Non-existing Maildir directory \'%s\'' % maildir
        return 1

    if dest_ics_dir and os.path.exists(dest_ics_dir) and not os.path.isdir(dest_ics_dir):
        print >>sys.stderr, '\'%s\' exists but is not a directory' % dest_ics_dir
        return 1

    if dest_ics and dest_ics_dir:
        print >>sys.stderr, 'Only one of --dest-ics and --dest-ics-dir can be used'
        return 1

    if dest_ics_dir:
        # move to absolute path, as we'll save it (and cache it)
        dest_ics_dir = os.path.abspath(dest_ics_dir)
        do_ics_dir(maildir, dest_ics_dir, force)
    else:
        # move to absolute path, as we'll save it (and cache it)
        if dest_ics is not None:
            dest_ics = os.path.abspath(dest_ics)

        do_ics_file(maildir, dest_ics, not_before, not_after, force)

    return 0


if __name__ == "__main__":
    try:
        ret = main(sys.argv)
        sys.exit(ret)
    except KeyboardInterrupt:
        pass

#!/usr/bin/env python
# -*- coding: utf-8 -*-
# vim: set ts=4 sw=4 et:
#
# Copyright (c) 2013 Vincent Untz <vincent@vuntz.net>
#
# License: MIT
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.
#


import errno
import os
import string
import sys

import ConfigParser
import datetime
import email
import hashlib
import optparse
import shutil



'''
Notes:
  - we do not use python-vobject for parsing vEvents, to allow using this
    without any other dependency than python.
  - we prefer X-GWRECORDID keys to UID when they exist, as GroupWise puts
    recurring events in multiple mails with the same UID.

How this works:
  - we have a cache of extracted vEvents from the maildir, to avoid re-parsing
    all mails all the time. We use a "recursive checksum" to validate that
    cache.
  - we also have a cache of DTSTART/DTEND for each vEvent, to avoid re-parsing
    the extracted vEvents. We also use a checksum to validate that cache.
  - we avoid rebuilding the iCalendar file if the caches are valid, and the
    time period for the vEvents to consider didn't change.
  - we simply concatenate all files together to build the resulting iCalendar
    file.
'''


ADD_ALARM = False
BROKEN_UTF8 = False
PREVIOUS_RUN_SECTION = 'previous'
VERBOSE = 0
VEVENTS_DATES = {}


def verbose_print(s, level = 1):
    global VERBOSE
    if VERBOSE >= level:
        print s


class LineUnwrapper:
    def __init__(self, s):
        self.lines = s.split('\n')
        self.lines_read = None
        self.saved = None

    def each_line(self):
        for line in self.lines:
            if line.startswith(' ') or line.startswith('\t'):
                if self.saved is None:
                    self.saved = ''
                    self.lines_read = []
                self.lines_read.append(line)
                self.saved += line.strip()
            else:
                if self.saved is not None:
                    retval = (self.lines_read, self.saved)
                    self.lines_read = [ line ]
                    self.saved = line.strip()
                    yield retval
                self.lines_read = [ line ]
                self.saved = line.strip()


def hash_from_file(filename):
    file_hash = hashlib.md5()

    fb = open(filename, 'rb')
    while True:
        buf = fb.read(4096)
        if not buf:
            break
        file_hash.update(buf)

    fb.close()

    return file_hash.hexdigest()


def hash_from_dir(directory):
    dir_hash = hashlib.md5()

    # We always need to examine files in the same order to make sure the hash
    # is always computed the same way
    filenames = os.listdir(directory)
    filenames.sort()

    for filename in filenames:
        path = os.path.join(directory, filename)
        if os.path.isdir(path):
            dir_hash.update(hash_from_dir(path))
        elif os.path.isfile(path):
            dir_hash.update(hash_from_file(path))
        else:
            verbose_print('Skipping compute of hash of \'%s\': not a file nor a directory.' % path, 1)

    return dir_hash.hexdigest()


def save_vevent(mail, vevent, uid, gwrecordid, dtstamp, dtstart, dtend, save_dir):
    global VEVENTS_DATES

    if gwrecordid:
        event_id = gwrecordid
    else:
        event_id = uid

    if event_id:
        filename = filter(lambda x: x in string.printable and x != '/', event_id)
    else:
        print >>sys.stderr, 'Ignoring event with no UID in \'%s\'' % mail
        return

    if dtstart is None:
        dtstart = dtend
    elif dtend is None:
        dtend = dtstart

    if dtstart is None:
        print >>sys.stderr, 'Ignoring event with no DTSTART in \'%s\'' % mail
        return

    path = os.path.join(save_dir, filename)
    if os.path.exists(path):
        old_dtstamp = None

        fb = open(path)
        content = LineUnwrapper(fb.read())
        lines = fb.readlines()
        fb.close()

        for (real_lines, line) in content.each_line():
            if not line.startswith('DTSTAMP:'):
                continue
            old_dtstamp = line[len('DTSTAMP:'):]
            break

        if dtstamp > old_dtstamp:
            verbose_print('Duplicate event \'%s\' with newer DTSTAMP, overwriting.' % event_id, 2)
        else:
            verbose_print('Duplicate event \'%s\' with same or older DTSTAMP, not overwriting.' % event_id, 2)
            return

    VEVENTS_DATES[event_id] = (dtstart, dtend)

    fp = open(path, 'w')
    fp.write(vevent.encode('utf-8'))
    fp.close()


def save_events_from_vcalendar(mail, vcalendar, save_dir):
    global ADD_ALARM

    content = LineUnwrapper(vcalendar)

    vevent = None
    uid = None
    gwrecordid = None
    dtstamp = None
    dtstart = None
    dtend = None

    need_valarm = ADD_ALARM
    valarm = '''BEGIN:VALARM
ACTION:DISPLAY
DESCRIPTION:REMINDER
TRIGGER;RELATED=START:-PT5M
END:VALARM'''
    # Two days in the past; this avoids any issue with timezones ;-)
    yesterday = (datetime.datetime.now() - datetime.timedelta(days=2))
    no_alarm_before = yesterday.strftime('%Y%m%d')

    for (real_lines, line) in content.each_line():
        if vevent is not None:
            vevent.extend(real_lines)
            # FIXME: what if there's a duplicate UID/DTSTAMP/etc. line? Is it correct to only keep first one?
            if line == 'END:VEVENT':
                # FIXME: generate UID if none?
                if need_valarm:
                    # insert before the END:VEVENT
                    vevent.insert(-len(real_lines), valarm)
                # Append final \n for EOL
                save_vevent(mail, '\n'.join(vevent)+'\n', uid, gwrecordid, dtstamp, dtstart, dtend, save_dir)
                vevent = None
            elif line.startswith('UID:') and uid is None:
                uid = line[len('UID:'):]
            elif line.startswith('X-GWRECORDID:') and gwrecordid is None:
                gwrecordid = line[len('X-GWRECORDID:'):]
            elif line.startswith('DTSTAMP:') and dtstamp is None:
                dtstamp = line[len('DTSTAMP:'):]
            elif line.startswith('DTSTART:') and dtstart is None:
                dtstart = line[len('DTSTART:'):]
                if need_valarm:
                    # event with a all-day DTSTART are most-likely all-day
                    # events
                    if len(dtstart) == len('19700101'):
                        need_valarm = False
                    elif dtstart < no_alarm_before:
                        need_valarm = False
            elif line.startswith('DTSTART;') and dtstart is None:
                dtstart = line[line.find(':')+1:]
                if need_valarm:
                    # event with a all-day DTSTART are most-likely all-day
                    # events
                    if len(dtstart) == len('19700101'):
                        need_valarm = False
                    elif dtstart < no_alarm_before:
                        need_valarm = False
            elif line.startswith('DTEND:') and dtend is None:
                dtend = line[len('DTEND:'):]
            elif line.startswith('DTEND;') and dtend is None:
                dtend = line[line.find(':')+1:]
            elif need_valarm:
                if line.startswith('X-GWITEM-TYPE:'):
                    if line[len('X-GWITEM-TYPE:'):].lower() != 'appointment':
                        need_valarm = False
                elif line.startswith('X-GWALLDAYEVENT:'):
                    if line[len('X-GWALLDAYEVENT:'):].lower() == 'true':
                        need_valarm = False
                elif line.startswith('X-MICROSOFT-CDO-ALLDAYEVENT:'):
                    if line[len('X-MICROSOFT-CDO-ALLDAYEVENT:'):].lower() == 'true':
                        need_valarm = False
                elif line == 'BEGIN:VALARM':
                    need_valarm = False
        elif line == 'BEGIN:VEVENT':
            vevent = real_lines
            uid = None
            gwrecordid = None
            dtstamp = None
            dtstart = None
            dtend = None

    if vevent is not None:
        verbose_print('Invalid vCalendar in \'%s\'.' % mail, 2)


def save_events_from_mail(filename, save_dir):
    global BROKEN_UTF8

    if not os.path.exists(filename):
        print >>sys.stderr, 'Non-existing mail \'%s\'???' % filename
        return

    fp = open(filename)
    msg = email.message_from_file(fp)
    fp.close()

    for part in msg.walk():
        if part.get_content_type() != 'text/calendar':
            continue

        charset = part.get_content_charset('ascii').lower()
        vcalendar = part.get_payload(decode = True).decode(charset)

        # This is really really ugly. We detect that we have a broken utf8 if
        # we have some unicode character in the decoded string.
        if charset == 'utf-8' and BROKEN_UTF8 and u'\xc3' in vcalendar:
            decoded = vcalendar

            # replace characters that got killed in MIME
            ## à
            decoded = decoded.replace(u'\xc3\x20', u'\xc3\xa0')
            ## è
            decoded = decoded.replace(u'\xc3\u0308', u'\xc3\xa8')
            ## ô
            decoded = decoded.replace(u'\xc3\u0301', u'\xc3\xb4')

            encoded = None
            for encoding in ['cp1252', 'iso-8859-15']:
                try:
                    encoded = decoded.encode(encoding)
                except UnicodeEncodeError:
                    continue
                break

            if encoded is None:
                # if we hit this, we finish breaking the UTF-8, and we'll have
                # the verbose_print from the last UnicodeDecodeError
                encoded = decoded.encode('iso-8859-15', 'replace')

            # we use 'replace' for the last decode since if we reached that
            # state, then there's simply nothing we can do to fix the UTF-8:
            # it's just plainly broken, not just double-encoded.
            try:
                reencoded = encoded.decode('utf-8')
            except UnicodeDecodeError:
                verbose_print('Mail \'%s\' contains really broken UTF-8.' % filename, 1)
                reencoded = encoded.decode('utf-8', 'replace')

            vcalendar = reencoded

        save_events_from_vcalendar(filename, vcalendar, save_dir)


def save_events_from_mails_in_dir(directory, save_dir):
    if not os.path.isdir(directory):
        print >>sys.stderr, 'Non-existing Maildir subdirectory \'%s\'???' % directory
        return

    for filename in os.listdir(directory):
        path = os.path.join(directory, filename)
        if not os.path.isfile(path):
            verbose_print('Skipping \'%s\': not a file.' % path, 1)
            continue
        save_events_from_mail(path, save_dir)


def save_events_from_maildir(directory, save_dir):
    for subdir in ['cur', 'new', 'tmp']:
        path = os.path.join(directory, subdir)
        save_events_from_mails_in_dir(path, save_dir)


def write_ics_from_dir(directory, dest, limit_past, limit_future):
    global VEVENTS_DATES

    if dest is not None:
        fp = open(dest, 'w')
    else:
        fp = sys.stdout

    fp.write('BEGIN:VCALENDAR\n')
    fp.write('PRODID:-//Vincent Untz//NONSGML maildir-to-ics//EN\n')
    fp.write('VERSION:2.0\n')

    filenames = os.listdir(directory)
    # sort to try to keep the generated file consistent if re-generated
    filenames.sort()

    for filename in filenames:
        if VEVENTS_DATES.has_key(filename):
            (dtstart, dtend) = VEVENTS_DATES[filename]
            if dtstart > limit_future:
                verbose_print('Skipping event \'%s\': too distant in the future.' % filename, 3)
                continue
            if dtend < limit_past:
                verbose_print('Skipping event \'%s\': too distant in the past.' % filename, 3)
                continue

        path = os.path.join(directory, filename)
        event = open(path, 'rb')
        while True:
            buf = event.read(4096)
            if not buf:
                break
            fp.write(buf)
        event.close()

    fp.write('END:VCALENDAR\n')
    if dest is not None:
        fp.close()


def main(args):
    global ADD_ALARM
    global BROKEN_UTF8
    global PREVIOUS_RUN_SECTION
    global VERBOSE
    global VEVENTS_DATES

    parser = optparse.OptionParser(usage='usage: %prog [options] --maildir=PATH')

    parser.add_option('--maildir', dest='maildir', default=None,
                      metavar="PATH",
                      help='Maildir directory to extract events from')
    parser.add_option('--ics', dest='ics', default=None,
                      metavar="FILE",
                      help='iCalendar file that will be created (if not used, will output ics to stdout)')
    parser.add_option('--not-before', dest='not_before', type='int', default=61,
                      metavar='N',
                      help='ignore events that happened before the last N days (default: 61, ie two months)')
    parser.add_option('--not-after', dest='not_after', type='int', default=182,
                      metavar='N',
                      help='ignore events that will happen after the next N days (default: 182, ie six months)')
    parser.add_option('--add-alarm', action='store_true',
                      default=False, dest='add_alarm',
                      help='automatically add 5 minutes alarm to non-all-day appointments')
    parser.add_option('--broken-utf8', action='store_true',
                      default=False, dest='broken_utf8',
                      help='assume that UTF-8 in mails is mis-encoded UTF-8 in Latin-1')
    parser.add_option('--force', '-f', action='store_true',
                      default=False, dest='force',
                      help='always regenerate ics file')
    parser.add_option('--verbose', '-v', action='count',
                      default=0, dest='verbose',
                      help='be verbose; use multiple times to add more verbosity (default: false)')

    (options, args) = parser.parse_args()

    maildir = options.maildir
    dest_ics = options.ics
    not_before = options.not_before
    not_after = options.not_after
    ADD_ALARM = options.add_alarm
    BROKEN_UTF8 = options.broken_utf8
    force = options.force
    VERBOSE = options.verbose

    if maildir is None:
        parser.error('--maildir argument is required')

    if not os.path.isdir(maildir):
        print >>sys.stderr, 'Non-existing Maildir directory \'%s\'' % maildir
        return 1

    # move to absolute path, as we use it to compute a hash
    maildir = os.path.abspath(maildir)
    # move to absolute path, as we'll save it
    if dest_ics is not None:
        dest_ics = os.path.abspath(dest_ics)

    now = datetime.datetime.now()
    past = now - datetime.timedelta(days=not_before)
    future = now + datetime.timedelta(days=not_after)
    limit_past = past.strftime('%Y%m%d')
    limit_future = future.strftime('%Y%m%d')

    xdg_cache_home = os.environ.get('XDG_CACHE_HOME', os.path.join(os.path.expanduser('~'), '.cache'))
    if not os.path.exists(xdg_cache_home):
        dirname = os.path.dirname(xdg_cache_home)
        if not os.path.exists(dirname):
            os.makedirs(dirname)
        os.mkdir(xdg_cache_home, 0700)

    cache_hash = hashlib.md5()
    cache_hash.update(maildir)

    info_dir = os.path.join(xdg_cache_home, 'maildir-to-ics', cache_hash.hexdigest())

    previous_run = ConfigParser.SafeConfigParser()
    previous_run_path = os.path.join(info_dir, 'previous-run.ini')
    if os.path.exists(previous_run_path):
        previous_run.read(previous_run_path)

    old_mails_hash = None
    old_vevents_cache_hash = None
    old_vevents_dates_hash = None
    old_limit_past = None
    old_limit_future = None
    old_ics = None

    if not previous_run.has_section(PREVIOUS_RUN_SECTION):
        previous_run.add_section(PREVIOUS_RUN_SECTION)

    if previous_run.has_option(PREVIOUS_RUN_SECTION, 'mails'):
        old_mails_hash = previous_run.get(PREVIOUS_RUN_SECTION, 'mails')
    if previous_run.has_option(PREVIOUS_RUN_SECTION, 'vevents_cache'):
        old_vevents_cache_hash = previous_run.get(PREVIOUS_RUN_SECTION, 'vevents_cache')
    if previous_run.has_option(PREVIOUS_RUN_SECTION, 'vevents_dates'):
        old_vevents_dates_hash = previous_run.get(PREVIOUS_RUN_SECTION, 'vevents_dates')
    if previous_run.has_option(PREVIOUS_RUN_SECTION, 'limit_past'):
        old_limit_past = previous_run.get(PREVIOUS_RUN_SECTION, 'limit_past')
    if previous_run.has_option(PREVIOUS_RUN_SECTION, 'limit_future'):
        old_limit_future = previous_run.get(PREVIOUS_RUN_SECTION, 'limit_future')
    if previous_run.has_option(PREVIOUS_RUN_SECTION, 'file'):
        old_ics = previous_run.get(PREVIOUS_RUN_SECTION, 'file')

    new_mails_hash = hash_from_dir(maildir)
    previous_run.set(PREVIOUS_RUN_SECTION, 'mails', new_mails_hash)

    cache_dir = os.path.join(info_dir, 'vevents')
    cache_dir_exists = os.path.exists(cache_dir)

    vevents_dates = os.path.join(info_dir, 'vevents_dates')
    if os.path.exists(vevents_dates):
        current_vevents_dates_hash = hash_from_file(vevents_dates)
    else:
        current_vevents_dates_hash = 'non-existing'

    need_to_rebuild_cache = False

    if force or old_mails_hash != new_mails_hash or \
        not cache_dir_exists or \
        old_vevents_dates_hash != current_vevents_dates_hash:
        need_to_rebuild_cache = True

    if not need_to_rebuild_cache:
        fp = open(vevents_dates, 'r')
        for line in fp.readlines():
            if line[-1] == '\n':
                line = line[:-1]
            elements = line.split('\t')
            if len(elements) != 3:
                verbose_print('Line \'%s\' in \'%s\' is invalid.' % (line, vevent_dates), 1)
                # file os corrupted, we'll regenerate it
                need_to_rebuild_cache = True
                VEVENTS_DATES = {}
                break
            (uid, dtstart, dtend) = elements
            VEVENTS_DATES[uid] = (dtstart, dtend)
        fp.close()

    if need_to_rebuild_cache:
        verbose_print('Rebuilding vEvents cache.', 1)
        if cache_dir_exists:
            shutil.rmtree(cache_dir)
        os.makedirs(cache_dir)
        save_events_from_maildir(maildir, cache_dir)

        new_vevents_cache_hash = hash_from_dir(cache_dir)
        previous_run.set(PREVIOUS_RUN_SECTION, 'vevents_cache', new_vevents_cache_hash)

        dates_hash = hashlib.md5()
        fp = open(vevents_dates, 'w')
        for (uid, (dtstart, dtend)) in VEVENTS_DATES.iteritems():
            line = '%s\t%s\t%s\n' % (uid, dtstart, dtend)
            fp.write(line)
            dates_hash.update(line)
        fp.close()

        new_vevents_dates_hash = dates_hash.hexdigest()
        previous_run.set(PREVIOUS_RUN_SECTION, 'vevents_dates', new_vevents_dates_hash)
    else:
        new_vevents_cache_hash = old_vevents_cache_hash
        new_vevents_dates_hash = old_vevents_dates_hash
        verbose_print('No need to rebuild vEvents cache: no change compared to last run.', 1)

    # regenerate ics if:
    #  - --force is used
    #  - events changed
    #  - range of dates to output changed
    #  - we output to stdout (so no old version)
    #  - last generated file is not the same as the new one, so we don't know
    #    if it's up-to-date
    #
    # relatedly: no need to regenerate previous-run.ini if ics isn't
    # regenerated
    if force or old_vevents_cache_hash != new_vevents_cache_hash or \
        old_vevents_dates_hash != new_vevents_dates_hash or \
        old_limit_past != limit_past or \
        old_limit_future != limit_future or \
        dest_ics is None or \
        old_ics != dest_ics or \
        not os.path.exists(dest_ics):
        verbose_print('Regenerating vCalendar.', 1)

        try:
            write_ics_from_dir(cache_dir, dest_ics, limit_past, limit_future)
        except IOError, e:
            # ignore broken pipe for stdout
            if dest_ics is None and e.errno != errno.EPIPE:
                raise e

        previous_run.set(PREVIOUS_RUN_SECTION, 'limit_past', limit_past)
        previous_run.set(PREVIOUS_RUN_SECTION, 'limit_future', limit_future)
        previous_run.set(PREVIOUS_RUN_SECTION, 'file', dest_ics or '')

        fp = open(previous_run_path, 'w')
        previous_run.write(fp)
        fp.close()
    else:
        verbose_print('No need to regenerate vCalendar: no change compared to last run.', 1)

    return 0


if __name__ == "__main__":
    try:
        ret = main(sys.argv)
        sys.exit(ret)
    except KeyboardInterrupt:
        pass
